{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_salary(i):\n",
    "    i = i.replace('k','').replace('M','').replace('$','').replace('£','')\n",
    "    return (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(i):\n",
    "    if type(i) != float:\n",
    "        try:\n",
    "            average = (clean_salary(i).split('–')[0] + clean_salary(i).split('–')[1]) / 2\n",
    "        except:\n",
    "            average = clean_salary(i)\n",
    "        return average\n",
    "    else:\n",
    "        return str(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ['buyer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8b4398316f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Jobs/full_jobs_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtitle_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "pre = 1\n",
    "post = 0\n",
    "full = pd.read_csv('./Jobs/full_jobs_df.csv')\n",
    "while pre != post:\n",
    "    for title_name in ss.copy():\n",
    "        pre = len(ss)\n",
    "        title_list = []\n",
    "        job_name = title_name.replace(' ','_')\n",
    "        job_url_name = job_name.replace('_','+')\n",
    "        pre_url = f'https://www.google.com/search?q={job_url_name}&ibp=htl;jobs#fpstate=tldetail&htidocid='\n",
    "    #     driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "\n",
    "        test_url = f'https://www.google.com/search?q={job_url_name}&ibp=htl;jobs'\n",
    "        driver.get(test_url)\n",
    "        proceed = 0\n",
    "    #     while proceed != 'Y':\n",
    "    #         proceed = input('Are You Ready To Proceed? (Y/N)')\n",
    "        for i in [pre_url+link.attrs['id'][4:] for link in BeautifulSoup(driver.page_source, 'lxml').find_all('div',{'jsname':'x5pWN'})]:\n",
    "            driver.get(i)\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        jobs = soup.find_all('li')\n",
    "        job_list = []\n",
    "        for job in jobs:\n",
    "            if (job.find('h2',{'jsname':'SBkjJd'}) != None) and (len(job.find_all('div',{'class':'tcoBdd'}))>1):\n",
    "                job_dic = {}\n",
    "                job_dic['title']= job.find('h2',{'jsname':'SBkjJd'}).text\n",
    "                title_list.append(job_dic['title'])\n",
    "                job_dic['company']=job.find('div',{'class':'pbHUre tcoBdd'}).text\n",
    "                job_dic['body']=job.find('span',{'style':'line-height:1.5em'}).text\n",
    "                job_dic['location']=job.find_all('div',{'class':'tcoBdd'})[1].text\n",
    "                try:\n",
    "                    job_dic['salary']=job.find('span',{'class':'zE8vH'}).text.replace('CA','')\n",
    "                except:\n",
    "                    job_dic['salary']=np.nan\n",
    "                job_dic['avg_salary']=avg(job_dic['salary'])\n",
    "                job_list.append(job_dic)\n",
    "#         full = pd.read_csv('./Jobs/full_jobs_df.csv')\n",
    "#        full.avg_salary = full.avg_salary.astype('object')\n",
    "        new = pd.DataFrame(job_list)\n",
    "        try:\n",
    "            new.salary = new.salary.astype('object')\n",
    "            full = pd.merge(full,new,how='outer')\n",
    "            full.drop_duplicates(inplace=True)\n",
    "            full.body = full.body.str.lower()\n",
    "            full.to_csv('./Jobs/full_jobs_df.csv',index=False)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    #     driver.quit()\n",
    "        print(f'We now have {full.shape[0]} jobs')\n",
    "        print(f'{full.avg_salary.notnull().sum()} of these jobs have a salary')\n",
    "#         time.sleep(5)\n",
    "    for title in title_list:\n",
    "        ss.append(title)\n",
    "        ss = list(dict.fromkeys(ss))\n",
    "    post = len(ss)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>body</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>digital marketing coordinator- tech | new york...</td>\n",
       "      <td>Informa</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Digital Marketing Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>at brooklyness we are creating a better commut...</td>\n",
       "      <td>BROOKLYNESS</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Digital Marketing Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123300</td>\n",
       "      <td>the digital marketing director will develop an...</td>\n",
       "      <td>Splits59</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>$85.6k–161k</td>\n",
       "      <td>Digital Marketing Director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128950</td>\n",
       "      <td>job description\\n\\nreuters news agency is seek...</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>$85.9k–172k</td>\n",
       "      <td>Senior Manager, Global Digital Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84450</td>\n",
       "      <td>love data and conversions? come join our team....</td>\n",
       "      <td>CB Insights</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>$57.9k–111k</td>\n",
       "      <td>Digital Marketing Manager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  avg_salary                                               body  \\\n",
       "0        NaN  digital marketing coordinator- tech | new york...   \n",
       "1        NaN  at brooklyness we are creating a better commut...   \n",
       "2     123300  the digital marketing director will develop an...   \n",
       "3     128950  job description\\n\\nreuters news agency is seek...   \n",
       "4      84450  love data and conversions? come join our team....   \n",
       "\n",
       "           company      location       salary  \\\n",
       "0          Informa  New York, NY          NaN   \n",
       "1      BROOKLYNESS      Anywhere          NaN   \n",
       "2         Splits59  New York, NY  $85.6k–161k   \n",
       "3  Thomson Reuters  New York, NY  $85.9k–172k   \n",
       "4      CB Insights  New York, NY  $57.9k–111k   \n",
       "\n",
       "                                      title  \n",
       "0             Digital Marketing Coordinator  \n",
       "1                    Digital Marketing Lead  \n",
       "2                Digital Marketing Director  \n",
       "3  Senior Manager, Global Digital Marketing  \n",
       "4                 Digital Marketing Manager  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "[job for job in jobs][0].find('span',{'class':'Cyt8W'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manually_get_job_data(job_name):\n",
    "    job_name = job_name.replace(' ','_')\n",
    "    job_url_name = job_name.replace('_','+')\n",
    "    pre_url = f'https://www.google.com/search?q={job_url_name}&ibp=htl;jobs#fpstate=tldetail&htidocid='\n",
    "    driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "    print( 'hi' ) \n",
    "    test_url = f'https://www.google.com/search?q={job_url_name}&ibp=htl;jobs'\n",
    "    driver.get(test_url)\n",
    "    proceed = 0\n",
    "    while proceed != 'Y':\n",
    "        proceed = input('Are You Ready To Proceed? (Y/N)').upper()\n",
    "    for i in [pre_url+link.attrs['id'][4:] for link in BeautifulSoup(driver.page_source, 'lxml').find_all('div',{'jsname':'x5pWN'})]:\n",
    "        driver.get(i)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    jobs = soup.find_all('li')\n",
    "    print(jobs)\n",
    "    job_list = []\n",
    "    for job in jobs:\n",
    "        if (job.find('h2',{'jsname':'SBkjJd'}) != None) and (len(job.find_all('div',{'class':'tcoBdd'}))>1):\n",
    "            job_dic = {}\n",
    "            job_dic['title']= job.find('h2',{'jsname':'SBkjJd'}).text\n",
    "            job_dic['company']=job.find('div',{'class':'pbHUre tcoBdd'}).text\n",
    "            job_dic['body']=job.find('span',{'style':'line-height:1.5em'}).text\n",
    "            job_dic['location']=job.find_all('div',{'class':'tcoBdd'})[1].text\n",
    "            try:\n",
    "                job_dic['salary']=job.find('span',{'class':'zE8vH'}).text.replace('CA','')\n",
    "            except:\n",
    "                job_dic['salary']=np.nan\n",
    "            job_dic['avg_salary']=avg(job_dic['salary'])\n",
    "            job_list.append(job_dic)\n",
    "    \n",
    "    \n",
    "    print(job_list)\n",
    "    print(job_dic)\n",
    "  #  full = pd.read_csv('./Jobs/full_jobs_df.csv')\n",
    "  #  full.avg_salary = full.avg_salary.astype('object')\n",
    "    new = pd.DataFrame(job_list)\n",
    "   # try:\n",
    "   #     new.salary = new.salary.astype('object')\n",
    "   #     full = pd.merge(full,new,how='outer')\n",
    "   #     full.drop_duplicates(inplace=True)\n",
    "   #     full.body = full.body.str.lower()\n",
    "   #     full.to_csv('./Jobs/full_jobs_df.csv',index=False)\n",
    "   # except:\n",
    "   #     pass\n",
    "\n",
    "    driver.quit()\n",
    "   # print(f'We now have {full.shape[0]} jobs')\n",
    "   # print(f'{full.avg_salary.notnull().sum()} of these jobs have a salary')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Job Titleremote\n",
      "hi\n",
      "Are You Ready To Proceed? (Y/N)Y\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter Job Title\")\n",
    "manually_get_job_data(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-af583a1c7196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'job_list' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeautifulSoup\t Keys\t avg\t clean_salary\t driver\t manually_get_job_data\t np\t numpy\t os\t \n",
      "pd\t post\t pre\t re\t requests\t selenium\t ss\t time\t webdriver\t \n",
      "word\t \n"
     ]
    }
   ],
   "source": [
    "who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                Type         Data/Info\n",
      "----------------------------------------------\n",
      "BeautifulSoup           type         <class 'bs4.BeautifulSoup'>\n",
      "Keys                    type         <class 'selenium.webdriver.common.keys.Keys'>\n",
      "avg                     function     <function avg at 0x105fc7b80>\n",
      "clean_salary            function     <function clean_salary at 0x105fc7820>\n",
      "driver                  WebDriver    <selenium.webdriver.chrom<...>4a6a951d761b1d191fa58e\")>\n",
      "manually_get_job_data   function     <function manually_get_job_data at 0x105fc7700>\n",
      "np                      module       <module 'numpy' from '/Li<...>kages/numpy/__init__.py'>\n",
      "numpy                   module       <module 'numpy' from '/Li<...>kages/numpy/__init__.py'>\n",
      "os                      module       <module 'os' from '/Libra<...>3.8/lib/python3.8/os.py'>\n",
      "pd                      module       <module 'pandas' from '/L<...>ages/pandas/__init__.py'>\n",
      "post                    int          0\n",
      "pre                     int          1\n",
      "re                      module       <module 're' from '/Libra<...>3.8/lib/python3.8/re.py'>\n",
      "requests                module       <module 'requests' from '<...>es/requests/__init__.py'>\n",
      "selenium                module       <module 'selenium' from '<...>es/selenium/__init__.py'>\n",
      "ss                      list         n=1\n",
      "time                    module       <module 'time' (built-in)>\n",
      "webdriver               module       <module 'selenium.webdriv<...>m/webdriver/__init__.py'>\n",
      "word                    str          remote\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
